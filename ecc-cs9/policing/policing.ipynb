{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26c094",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"policing.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fd82a-80f0-4835-9406-896fa3e3e406",
   "metadata": {},
   "source": [
    "# The **Stanford Open Policing** Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e74d916-9af0-4980-80be-9c278fddd5f1",
   "metadata": {},
   "source": [
    "**Estimated Time**: 30 Minutes <br>\n",
    "**Developers**: Bing Concepcion and James Geronimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9e810-36d7-48b0-b9dc-79e495883317",
   "metadata": {},
   "source": [
    "**Note**: This notebook is adapted from the open-source work of the [**Stanford Open Policing Project**](https://openpolicing.stanford.edu/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f314b7-b147-4c8a-8d19-09e736ff5bce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e10f5-20cc-4866-bc1a-bf488b38d349",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6b51d-7bbd-4a14-847c-6ccb93ab0b32",
   "metadata": {},
   "source": [
    "1. Background <br>\n",
    "2. Setup, Sampling, and Subsetting <br>\n",
    "3. Exploring Trends (Counts and Proportions)\n",
    "4. Benchmark Analysis\n",
    "5. Veil of Darkness Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e15878-2f1d-4b66-a133-fccbac1c0be9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a701cab-1153-4e0d-9511-93f804af68a7",
   "metadata": {},
   "source": [
    "## 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3135fc-4b1c-43d7-ab4b-6b3ef561ad03",
   "metadata": {},
   "source": [
    "On a typical day in the United States, police officers make more than 50,000 traffic stops. The Stanford Open Policing Project is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Their goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95ab9e-234c-4e18-a15c-a9082d609a7d",
   "metadata": {},
   "source": [
    "Below, we've linked a YouTube video from Stanford's Computational Policy Lab, which provides a brief overview of the Stanford Open Policing Project. We highly encourage you to give it a watch, as content throughout this notebook will relate back to this video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509e964-b064-4c20-b464-dea70a12f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"iwOWcuFjNfw\", width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab468a1-b084-498d-9da6-3d76555b14c5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.1**: Fill in the blank: Black and Hispanic drivers are ticketed, searched and arrested at __________ rates than white drivers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1d2a9-a6cd-4468-aa7a-7559e28424cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.2**: Fill in the blank. \n",
    "\n",
    "Black and Hispanic drivers are searched on the basis of _______ evidence than white drivers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208e259-f2e8-4a6e-96f0-ad31fbbc1f02",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.3**: What effect did 8 states legalizing recreational marijuana have on the number of searches? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e5c1b-9639-45b5-9259-50b95a19169d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0675222-c226-4e96-a0f0-c99b95413643",
   "metadata": {},
   "source": [
    "## 2. Setup, Sampling, and Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e26922-d39a-4b28-baa9-524b6984692b",
   "metadata": {},
   "source": [
    "Just importing some libraries we'll need for the analysis we will partake in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5c499-018c-44b7-a58d-636047dcb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from suntime import Sun\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff5397-63d0-4ed5-8c17-cc4e131f84cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You may have noticed that a dataset was not given for the assignment. That's because you will be retrieving it yourself! \n",
    "\n",
    "**Question 2.1**: From the project's [Data page](https://openpolicing.stanford.edu/data/), download the *CSV* file corresponding to *Los Angeles, California*, and drag it into the current working directory of this notebook. Once you've successfully done this, the cell below should generate a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a906f-823e-48ff-9fe9-383325cfb75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops = ...\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a4d94",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94af552-9d3d-4afb-9e41-11e3a718c7f9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Before diving into any heavy-duty analysis, it's important to understand the size of the dataset we're working with.\n",
    "\n",
    "**Question 2.2**: Calculate the number of rows in `stops`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11096d72-ebdb-4024-9044-a6c5007d8d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_rows = ...\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb98c6d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7126031-6c06-49a6-a3cf-de52823684ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Our dataset contains over 5 million traffic stops. Working with a dataset of this size can quickly become computationally expensive. It can slow down operations like filtering, joining, and plotting, especially on machines with limited memory.\n",
    "\n",
    "To make our workflow more efficient without sacrificing the integrity of our analysis, we'll take a random 10% sample of the data. This allows us to get a reliable sense of overall patterns and relationships, without requiring full-scale processing of the entire dataset.\n",
    "\n",
    "> Of course, for final results or publication-level accuracy, we’d want to use the full dataset—but for exploratory analysis, a random sample often gets us most of the way there.\n",
    "\n",
    "**Question 2.3**: Generate a 10% random sample of using `stops`. The `sample` function ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)) will be particuarly useful here. Please set `random_state` to 42 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0346a-a604-434e-ba26-f947b3915a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_sample = ...\n",
    "len(stops_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ab3ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232c10a-3a38-4649-87e3-d166d0a19273",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.4**: What is the granularity of the data? Does this change at all by the random sample we just did?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154b973-ceeb-4c43-a4b7-ad4d056ce14f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.5**: Take a look at the provided feature set that came with the data. What additional feature would be interesting to add in this dataset? How might it add to an analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871feb99-107c-496c-8a97-e9887295b34b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Our dataset spans multiple years. But after some digging, you'll notice that we only have partial data for 2018, which may bias our analysis. To ensure consistency, we’ll focus only on the years we have complete data for, 2010–2017.\n",
    "\n",
    "**Question 2.6**: Extract the year from the date column and filter accordingly. You'll first want to convert the data in the `\"date\"` column to a `datatime` type. `to_datetime` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)). Then, create a new column `\"year\"`, which is simply the year at that given row. The `dt` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html) will be helpful here, and note that a `year` attribute does exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8037f-d9aa-44ea-ab0c-af0e0b0b8ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_sample['date'] = ...\n",
    "stops_sample['year'] = ...\n",
    "stops_sample = ...\n",
    "stops_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0ca0a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089b0ca-2824-4236-9d9f-a5efccc0bd3f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The dataset includes both pedestrian and vehicular stops. For this notebook, we'll be focusing our analysis on traffic enforcement, so we’ll zoom in on just the vehicular stops for now.\n",
    "\n",
    "> Do note that we can perform the same analysis on vehicular stops as we do to pedestrian stops. We are simply going to remove pedestrian stops for consistency of our analysis and since vehicular stops were the primary motivation of the Stanford Open Policing Project.\n",
    "\n",
    "**Question 2.7**: Filter the data so `stops_sample` only contains rows corresponding to vehicular stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810719e-941f-46d4-940f-83163dfa380d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_sample = stops_sample[stops_sample['type'] == 'vehicular']\n",
    "len(stops_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9737f44",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b7a12-8329-4436-87ea-a5102aaa88d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba33b53-34e7-4657-9f7b-53c2a4b18539",
   "metadata": {},
   "source": [
    "## 3. Exploring Trends (Counts and Proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17528f1b-dd4a-4255-bf1c-09821fb929ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that we’ve filtered to just vehicular stops from 2010–2017, let’s take a look at how the number of stops changed over time and whether those patterns differ by race.\n",
    "\n",
    "**Question 3.1**: Using the `\"year\"` column we defined in Question 2.6, get the count for the number of stops per year. Make sure to sort your result by year, starting at 2010 and ending at 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a1c55-5ae6-46d3-b0d9-81848e6338c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_per_year = ...\n",
    "stops_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef04b9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bac7c-5eca-4bdf-adc8-f8018f50a839",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.2**: Using similar logic as Question 3.1, calculate the stop counts by race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d258edf-1342-4660-a959-ef2fe4b55d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_by_race = ...\n",
    "stops_by_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776150b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4e593-0ed8-42ba-a8fa-74b071f8fa62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "So far, we've narrowed our dataset to a manageable sample of vehicular stops, and carried out the calculations to understand the volume of traffic stops over time and by race.\n",
    "\n",
    "It's time to build some data visualizations that will provide a strong indicator for trends and disparities. \n",
    "\n",
    "**Question 3.3**: Build a line plot that visualizes the number of stops of each race per year. You'll first want to group by the `\"year\"` and `\"subject_race\"` columns and aggregate the data somehow to generate a new `DataFrame` called `stops_by_year_race`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3fc9f-6014-48c8-b894-0665d2016676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_by_year_race = ...\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data= ...\n",
    "    x= ...\n",
    "    y= ...\n",
    "    hue= ...\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('Counts of Traffic Stops by Year and Race')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Stops')\n",
    "plt.legend(title='Race')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4580dfa-9535-469c-ae16-c6567cebf5ab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.4**: Are there any significant disparities in the plot above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b46871-a42f-4d0b-b409-85405f6ee8e4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.5**: Name at least one limitation of our data/plot, and explain how you could circumvent this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4404b-a777-4098-bfdf-7c203276175d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "So far, we’ve looked at the raw number of stops each year, broken down by race. While this helps us understand absolute trends, it doesn’t tell us everything.\n",
    "\n",
    "> Imagine one year had a spike in overall stops — it would likely inflate all racial group counts, even if their relative share of stops didn’t change.\n",
    "\n",
    "That’s why we now turn to proportional analysis. Instead of asking:\n",
    "\n",
    "> \"How many Black drivers were stopped in 2016?\" <br> We now ask: \"What percentage of all drivers stopped in 2016 were Black?\"\n",
    "\n",
    "This helps us determine whether certain groups were being stopped more or less often relative to others, regardless of how much total enforcement was happening.\n",
    "\n",
    "**Question 3.6**: Below, we've defined a `\"total_stops_in_year\"` column, which is the total number of stops conduct in each year. Use this to calculate a new column called `\"prop_stop\"` — the proportion of stops each race accounted for within each year. Then, visualize these proportions across years in a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7c764-ee09-4c30-8648-9ca6a9e84c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_by_year_race['total_stops_in_year'] = ...\n",
    "stops_by_year_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325b39d-3c63-42ad-b1d3-0dc129a0db19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_by_year_race['prop_stops'] = ...\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=stops_by_year_race,\n",
    "    x='year',\n",
    "    y='prop_stops',\n",
    "    hue='subject_race',\n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "plt.title('Proportion of Traffic Stops by Race Over Time (Sample)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of Stops')\n",
    "plt.legend(title='Race')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fafe6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d1a6d-ed6f-42f1-b816-b6203a2c3adb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.7**: What differences do you see between the \"count\" and \"proportion\" plots? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148a9b3-6629-4797-a2c8-aba0e28bc45e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.8**: Name at least one aspect of either visualization that surprised you the most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771893b1-103d-48af-ab21-19d1eb168878",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fa84e-0eb7-492a-91d5-e44a57adc2c6",
   "metadata": {},
   "source": [
    "## 4. Benchmark Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad1378-e3ea-4de7-8f96-5f8051d4503e",
   "metadata": {},
   "source": [
    "Earlier, we examined how traffic stops were distributed by race. But to interpret those results meaningfully, we need a baseline. To do this, we will compare the racial makeup of stops to the racial demographics of Los Angeles.\n",
    "\n",
    "Below, we've provided the Los Angeles population demographic from 2017 and stored it in the `DataFrame` `population_2017`. These numbers were taken from [Census Reporter](https://censusreporter.org/profiles/14000US06037201700-census-tract-2017-los-angeles-ca/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eccee0-5fd8-4800-a70f-6f6da2383262",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2017 = pd.DataFrame({\n",
    "    'subject_race': [\n",
    "        'white', 'black', 'asian/pacific islander', 'other', 'hispanic'\n",
    "    ],\n",
    "    'num_people': [\n",
    "        1092687, 316317, 456460+4536, 24178+6005+135551, 1822163\n",
    "    ]\n",
    "})\n",
    "\n",
    "population_2017['population_prop'] = population_2017['num_people'] / population_2017['num_people'].sum()\n",
    "population_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672a5e2-8b0d-4314-9947-c30243d3c5ab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Before we use `population_2017` we need to filter our data to the year 2017.\n",
    "\n",
    "**Question 4.1**: Filter the `stops_by_year_race` to 2017 and assign it to `stops_2017`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5eb73a-6eb6-4709-afc0-010b173dcd4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops_2017 = ...\n",
    "stops_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a12a5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d3e75-531c-414f-868e-27458d47c6b2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that we've filtered our dataset to only stops in 2017, we can now get ready to compare stops for each racial group relative to their population proportions.\n",
    "\n",
    "\n",
    "**Question 4.2**: Let's merge these `stops_2017` and `population_2017` by the `subject_race` column and assign this merged DataFrame to `benchmark_df`. Then, create a `stop_rate_per_person` column which shows the number of stops per person for each racial group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c614c-6020-4fef-b982-051fea21a8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark_df = ...\n",
    "benchmark_df['stop_rate_per_person'] = ...\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4158484",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4942a-2b92-4163-a52b-4dba66f443bc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Numerically, we see some signficant differences amongst the propoprtion of stops to the stop rate per person. Let's visualize the stop rate per person so we can more clearly see these differences.\n",
    "\n",
    "**Question 4.3**: Create a bar plot with the x-axis representing the racial groups and the y-axis representing the corresponding stop rate per person. Be sure to provide appropriate axis labels and title!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446a7b8-ccb8-4640-962d-f1196ef346d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(\n",
    "    data= ...\n",
    "    x= ...\n",
    "    y= ...\n",
    ")\n",
    "\n",
    "plt.title('Stop Rate per Person by Race (2017, Sampled Data)')\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Stop Rate (Stops per Person)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774cc93a-dc14-48d2-866e-b3739d5fa3f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.4**: Based on the stop rate per person bar plot, what insights can you draw about how race affects an individuals chance of being stopped in Los Angeles? Which racial groups are stopped at disproportionately high rates? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a762f6-3d26-4c01-addc-54ef965bb543",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.5**: How does the stop rate per person plot differ from early graphs looking at number and proportions of stops by race? Why is it important to account for population size, rather than just looking at raw counts or proportions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647bc83-addb-4cf6-b101-fa9e8ed4ed43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da7f07-a93c-4132-97f2-0ba906b426e6",
   "metadata": {},
   "source": [
    "## 5. Veil of Darkness Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41659325-581d-4010-a3b4-7b8435014093",
   "metadata": {},
   "source": [
    "The **Veil of Darkness** hypothesis explores whether the proportion of Black drivers that are stopped changes at all when it becomes dark. This is proposed under the idea that officers can no longer perceive race before making the stop.\n",
    "\n",
    "We essentially explore through this test whether or not racial bias exists, given we find a signficant difference in the proportion of Black drivers stopped at night. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2106d-a51c-4190-9bf0-380e07f9753f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In order to perform this analysis, we need to know exactly when it was light and dark on each date in our dataset. Note that we can't simply assume all days get dark at a specific time because the hours of daylight change across seasons. Thus, we must calculate the sunrise and sunset times for each unique date.\n",
    "\n",
    "**Question 5.1**: We have already defined the geographic coordinates of Los Angeles and the solar calculator you will need to use. Your task is to compute the sunrise and sunset times for each date to build a DataFrame `sun_times`, which stores the local sunrise and sunset time for each stop date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1229b-d9bd-4e0c-84da-05425d448591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coordinates for Los Angeles\n",
    "center_lat = 34.0549\n",
    "center_lng = -118.2426\n",
    "\n",
    "# Solar calculator\n",
    "sun = ...\n",
    "\n",
    "# Get sun times for each unique date\n",
    "sun_times = []\n",
    "dates = stops_sample['date'].unique()\n",
    "for date in dates:\n",
    "    sunrise_utc = ...\n",
    "    sunset_utc = ...\n",
    "    sunrise_la = ...\n",
    "    sunset_la = ...\n",
    "    sun_times.append({'date': date, 'sunrise': sunrise_la, 'sunset': sunset_la}) \n",
    "sun_times = ...\n",
    "\n",
    "sun_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eacaae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de1920-f34a-453b-8f09-43d68b6b44b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that we have sunrise and sunset times for each unique date, we can determine whether a specific stop in our `stops_sample` DataFrame happened during daylight or darkness.\n",
    "\n",
    "**Question 5.2**: Join the sunrise and sunset times to our `stops_sample` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324fa93-df42-435c-8575-d8418179c987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge sun times with stops\n",
    "vod_stops = stops_sample.merge(sun_times, on='date', how='left')\n",
    "vod_stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea21c7-8eb7-4968-afd4-8ae2f6b75d51",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "`vod_stops` is a DataFrame that has information on each of the stops from `stops_sample` in addition to each day's sunrise and sunset times. We should define what stops were made in the dark to help us conduct the analysis. We have pre-defined the minute values for each of the stop, sunrise, and sunset times. \n",
    "\n",
    "**Question 5.3**: In `vod_stops`, create a `\"is_dark\"` column that is set to `True` when `stop_minute` is strictly greater than `sunset_minute` and strictly less than `sunrise_minute`, but is `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d39504-9fe6-4277-a2c9-f1f3d308285e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert stop, sunrise, and sunset time to minutes\n",
    "vod_stops['stop_minute'] = pd.to_datetime(vod_stops['time'], format='%H:%M:%S').dt.hour * 60 + pd.to_datetime(vod_stops['time'], format= ...\n",
    "vod_stops['sunrise_minute'] = pd.to_datetime(vod_stops['sunrise'], format='%H:%M:%S').dt.hour * 60 + pd.to_datetime(vod_stops['sunrise'], format= ...\n",
    "vod_stops['sunset_minute'] = pd.to_datetime(vod_stops['sunset'], format='%H:%M:%S').dt.hour * 60 + pd.to_datetime(vod_stops['sunset'], format= ...\n",
    "\n",
    "# Define \"is_dark\" column\n",
    "vod_stops['is_dark'] = (vod_stops['stop_minute'] > (vod_stops['sunset_minute'] + 60)) | \\\n",
    "                        ...\n",
    "vod_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a8601",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f55d78-055a-4b50-aaed-d67ac140fd1f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that we've determined whether each stop occurred during darkness or daylight, we're ready to set up our Veil of Darkness analysis.\n",
    "\n",
    "**Question 5.4**: Filter `vod_stops` to only include stops involving Black and White drivers to simplify our analysis to two groups. Then, create a new indicator column `is_black` that is `1` if the stopped driver was Blakc, and `0` if the stopped driver was White. After correctly implementing these instructions and running the cell, a \"Logit Regression Results\" table should appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb2e26-a7cc-4814-9445-11aaddc6ef33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vod_stops = ...\n",
    "vod_stops['is_black'] = (vod_stops['subject_race'] = ...\n",
    "\n",
    "# Logistic regression model\n",
    "vod_stops['is_dark'] = ...\n",
    "model = ...\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c1b3d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q27\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7d327e-c53d-4ad3-9d52-63e0254897a5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.5**: What does the statistically significant coefficient on `is_dark` suggest about how race may influence traffic stops after dark?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6d0ac-cd38-4789-8043-d66adbd403d0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.6**: How does this finding compare to the original Veil of Darkness hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4e374-f284-4d9d-884f-d1af72acfa4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ce4d7-132d-486a-a5d2-09c855a3c1cb",
   "metadata": {},
   "source": [
    "Hurray! You're done with this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68517073",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "These are some submission instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e099ab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01425b9b",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops_sample == stops_sample[stops_sample['type'] == 'vehicular'], \"Make sure to convert the 'date' column to datetime format.\")\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops_per_year == stops_sample['year'].value_counts().sort_index(), 'Make sure to count the number of stops per year and sort by year.')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q12": {
     "name": "q12",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops_by_race == stops_sample['subject_race'].value_counts(), 'Make sure to count the number of stops by subject race.')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q16": {
     "name": "q16",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops_by_year_race['total_stops_in_year'] == stops_by_year_race.groupby('year')['num_stops'].transform('sum'), 'Make sure to count total stops in each year.')\n>>> assert (stops_by_year_race['prop_stops'] == stops_by_year_race['num_stops'] / stops_by_year_race['total_stops_in_year'], 'Make sure to calculate the proportion of stops for each race per year.')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q19": {
     "name": "q19",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops_2017 == stops_by_year_race[stops_by_year_race['year'] == 2017], ' Make sure to filter stops_by_year')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q20": {
     "name": "q20",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (benchmark_df == pd.merge(stops_2017, population_2017, on='subject_race'), ' Make sure to filter stops_by_year')\n>>> assert (benchmark_df['stop_rate_per_person'] == benchmark_df['num_stops'] / benchmark_df['num_people'], 'Make sure to calculate the stop rate per person.')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q24": {
     "name": "q24",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'date' in sun_times.columns and 'sunrise' in sun_times.columns and ('sunset' in sun_times.columns), \"Columns 'date', 'sunrise', and 'sunset' must exist in sun_times DataFrame.\"\n>>> assert len(sun_times) == len(stops_sample['date'].unique()), 'Each unique date in stops_sample should correspond to one row in sun_times.'\n>>> from datetime import datetime\n>>> sunrise_times = sun_times['sunrise'].apply(lambda t: datetime.strptime(t, '%H:%M:%S').time())\n>>> sunset_times = sun_times['sunset'].apply(lambda t: datetime.strptime(t, '%H:%M:%S').time())\n>>> assert all(sunrise_times < sunset_times), \"Each day's sunrise time should be earlier than its sunset time.\"\n>>> assert all(sunrise_times.apply(lambda t: 4 <= t.hour <= 8)), 'Sunrise in Los Angeles should typically occur between 4 AM and 8 AM.'\n>>> assert all(sunset_times.apply(lambda t: 16 <= t.hour <= 21)), 'Sunset in Los Angeles should typically occur between 4 PM and 9 PM.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q26": {
     "name": "q26",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert all((col in vod_stops.columns for col in ['stop_minute', 'sunrise_minute', 'sunset_minute', 'is_dark'])), \"Make sure the columns 'stop_minute', 'sunrise_minute', 'sunset_minute', and 'is_dark' all exist.\"\n>>> assert vod_stops[['stop_minute', 'sunrise_minute', 'sunset_minute']].applymap(lambda x: isinstance(x, (int, float))).all().all(), 'Time conversion failed — minutes columns should be numeric.'\n>>> assert vod_stops['stop_minute'].between(0, 1440).all(), 'stop_minute should be between 0 and 1440.'\n>>> assert vod_stops['sunrise_minute'].between(0, 1440).all(), 'sunrise_minute should be between 0 and 1440.'\n>>> assert vod_stops['sunset_minute'].between(0, 1440).all(), 'sunset_minute should be between 0 and 1440.'\n>>> violations = vod_stops[vod_stops['is_dark'] & vod_stops['stop_minute'].between(vod_stops['sunrise_minute'] - 60, vod_stops['sunset_minute'] + 60)]\n>>> assert len(violations) == 0, 'Some rows are incorrectly marked as dark.'\n>>> non_dark = vod_stops[~vod_stops['is_dark']]\n>>> assert len(non_dark) > 0, 'No non-dark rows detected — check your time comparison logic.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q27": {
     "name": "q27",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert all((col in vod_stops.columns for col in ['subject_race', 'is_black', 'is_dark', 'stop_minute'])), \"Make sure all columns ['subject_race', 'is_black', 'is_dark', 'stop_minute'] exist.\"\n>>> assert set(vod_stops['subject_race'].unique()).issubset({'black', 'white'}), \"The dataset should only include rows where subject_race is 'black' or 'white'.\"\n>>> assert vod_stops.groupby('subject_race')['is_black'].nunique().to_dict() == {'black': 1, 'white': 1}, \"is_black should be 1 for 'black' and 0 for 'white' subjects.\"\n>>> assert vod_stops['is_dark'].dtype in [int, 'int64', 'int32'], 'is_dark should be integer (0/1).'\n>>> assert vod_stops['is_black'].dtype in [int, 'int64', 'int32'], 'is_black should be integer (0/1).'\n>>> assert 'is_dark' in model.params.index and 'stop_minute' in model.params.index, \"The logistic model must include both 'is_dark' and 'stop_minute' as predictors.\"\n>>> assert model.converged, 'The logistic regression model failed to converge.'\n>>> assert len(vod_stops) > 50, 'Too few observations — check your filtering logic.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops == pd.read_csv('ca_los_angeles_2020_04_01.csv', dtype={3: str}), 'Make sure to read the CSV file with the correct dtype for column 3.')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (num_rows == stops.shape[0], 'Make sure to read the CSV file with the correct dtype for column 3.')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops_sample == stops.sample(frac=0.1, random_state=42), 'Make sure to sample 10% of the data with correct random_state')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (stops_sample['date'] == pd.to_datetime(stops_sample['date']), \"Make sure to convert the 'date' column to datetime format.\")\n>>> assert (stops_sample['year'] == stops_sample['date'].dt.year, \"Make sure to extract the year from the 'date' column.\")\n>>> assert (stops_sample == stops_sample[stops_sample['year'] < 2018], 'Make sure to filter the DataFrame for years before 2018.')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
